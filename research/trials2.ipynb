{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, AutoModelForSeq2SeqLM\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/abhinavm16104-delhi-skill-and-entrepreneurship-university/briefly-v1/runs/9f0s9g0e?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x216f39e9240>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "\n",
    "wandb.init(\n",
    "    project=\"briefly-v1\",  \n",
    "    name=\"briefly-trialsv1\",    \n",
    "    config={                   \n",
    "        \"learning_rate\": 2e-5,\n",
    "        \"epochs\": 4,\n",
    "        \"batch_size\": 16\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "billsum = load_dataset(\"billsum\", split=\"ca_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "billsum = billsum.train_test_split(test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'The people of the State of California do enact as follows:\\n\\n\\nSECTION 1.\\nSection 51203 of the Government Code is amended to read:\\n51203.\\n(a) The assessor shall determine the current fair market value of the land as if it were free of the contractual restriction pursuant to Section 51283. The Department of Conservation or the landowner, also referred to in this section as “parties,” may provide information to assist the assessor to determine the value. Any information provided to the assessor shall be served on the other party, unless the information was provided at the request of the assessor, and would be confidential under law if required of an assessee.\\n(b) Within 45 days of receiving the assessor’s notice pursuant to subdivision (a) of Section 51283 or Section 51283.4, if the Department of Conservation or the landowner believes that the current fair market valuation certified pursuant to subdivision (b) of Section 51283 or Section 51283.4 is not accurate, the department or the landowner may request formal review from the county assessor in the county considering the petition to cancel the contract. The department or the landowner shall submit to the assessor and the other party the reasons for believing the valuation is not accurate and the additional information the requesting party believes may substantiate a recalculation of the property valuation. The assessor may recover his or her reasonable costs of the formal review from the party requesting the review, and may provide an estimate of those costs to the requesting party. The recovery of these costs from the department may be deducted by the city or county from cancellation fees received pursuant to this chapter prior to transmittal to the Controller for deposit in the Soil Conservation Fund. The assessor may require a deposit from the landowner to cover the contingency that payment of a cancellation fee will not necessarily result from the completion of a formal review. This subdivision shall not be construed as a limitation on the authority provided in Section 51287 for cities or counties to recover their costs in the cancellation process, except that the assessor’s costs of conducting a formal review shall not be borne by the nonrequesting party.\\n(1) If no request is made within 45 days of receiving notice by certified mail of the valuation, the assessor’s valuation shall be used to calculate the fee.\\n(2) Upon receiving a request for formal review, the assessor shall formally review his or her valuation if, based on the determination of the assessor, the information may have a material effect on valuation of the property. The assessor shall notify the parties that the formal review is being undertaken and that information to aid the assessor’s review shall be submitted within 30 days of the date of the notice to the parties. Any information submitted to the assessor shall be served on the other party who shall have 30 days to respond to that information to the assessor. If the response to the assessor contains new information, the party receiving that response shall have 20 days to respond to the assessor as to the new information. All submittals and responses to the assessor shall be served on the other party by personal service or an affidavit of mailing. The assessor shall avoid ex parte contacts during the formal review and shall report any such contacts to the department and the landowner at the same time the review is complete. The assessor shall complete the review no later than 120 days of receiving the request.\\n(3) At the conclusion of the formal review, the assessor shall either revise the cancellation valuation or determine that the original cancellation valuation is accurate. The assessor shall send the revised valuation or notice of the determination that the valuation is accurate to the department, the landowner, and the board or council considering the petition to cancel the contract. The assessor shall include a brief narrative of what consideration was given to the items of information and responses directly relating to the cancellation value submitted by the parties. The assessor shall give no consideration to a party’s information or response that was not served on the other party. If the assessor denies a formal review, a brief narrative shall be provided to the parties indicating the basis for the denial, if requested.\\n(c) For purposes of this section, the valuation date of any revised valuation pursuant to formal review or following judicial challenge shall remain the date of the assessor’s initial valuation, or his or her initial recomputation pursuant to Section 51283.4. For purposes of cancellation fee calculation in a tentative cancellation as provided in Section 51283, or in a recomputation for final cancellation as provided in Section 51283.4, a cancellation value shall be considered current for one year after its determination and certification by the assessor.\\n(d) Notwithstanding any other provision of this section, the department and the landowner may agree on a cancellation valuation of the land. The agreed valuation shall serve as the cancellation valuation pursuant to Section 51283 or Section 51283.4. The agreement shall be transmitted to the board or council considering the petition to cancel the contract.\\n(e) If a contract with a city or county includes an additional cancellation fee pursuant to Section 51240, the department shall provide a preliminary valuation to the county assessor of the county in which the land is located and the board of supervisors or the city council at least 60 days prior to the effective date of the final cancellation valuation pursuant to subdivision (d). The preliminary valuation shall include a description of the rationale and facts considered by the department in determining the cancellation value. The assessor may provide comments on the preliminary valuation to the board of supervisors or city council. The board of supervisors or city council may provide comments on the preliminary valuation and cancellation value, if submitted, to the department. Prior to determining the final cancellation valuation, the department shall consider the comments of the board or council concerning the preliminary valuation and cancellation valuation, if submitted.\\n(f) This section represents the exclusive administrative procedure for appealing a cancellation valuation calculated pursuant to this section. The Department of Conservation shall represent the interests of the state in the administrative and judicial remedies for challenging the determination of a cancellation valuation or cancellation fee.',\n",
       " 'summary': 'Existing law establishes the California Land Conservation Act of 1965, otherwise known as the Williamson Act, and authorizes a city or county to enter into 10-year contracts with owners of land devoted to agricultural use, whereby the owners agree to continue using the property for that purpose, and the city or county agrees to value the land accordingly for purposes of property taxation, as specified. Existing law provides for the procedure to cancel a contract entered into under these provisions, and provides that the landowner and the Department of Conservation may agree on the cancellation value of the land.\\nThis bill would require the department to provide a preliminary valuation of the land to the county assessor and the city council or board of supervisors at least 60 days prior to the effective date of the agreed upon cancellation valuation if the contract includes an additional cancellation fee, as specified.',\n",
       " 'title': 'An act to amend Section 51203 of the Government Code, relating to local government.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billsum['train'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"google-t5/t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_prompt = \"Summarize: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(txt):\n",
    "    inputs = [prefix_prompt + doc for doc in txt[\"text\"]]\n",
    "    tokenix = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "    labels = tokenizer(text_target=txt[\"summary\"], max_length=128, truncation=True)\n",
    "    tokenix[\"labels\"] = labels[\"input_ids\"]\n",
    "    return tokenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 927/927 [00:00<00:00, 1032.30 examples/s]\n",
      "Map: 100%|██████████| 310/310 [00:00<00:00, 970.33 examples/s] \n"
     ]
    }
   ],
   "source": [
    "billsum_tokeniz = billsum.map(preprocess_text, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationModule(name: \"rouge\", module_type: \"metric\", features: [{'predictions': Value(dtype='string', id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='sequence'), length=-1, id=None)}, {'predictions': Value(dtype='string', id='sequence'), 'references': Value(dtype='string', id='sequence')}], usage: \"\"\"\n",
       "Calculates average rouge scores for a list of hypotheses and references\n",
       "Args:\n",
       "    predictions: list of predictions to score. Each prediction\n",
       "        should be a string with tokens separated by spaces.\n",
       "    references: list of reference for each prediction. Each\n",
       "        reference should be a string with tokens separated by spaces.\n",
       "    rouge_types: A list of rouge types to calculate.\n",
       "        Valid names:\n",
       "        `\"rouge{n}\"` (e.g. `\"rouge1\"`, `\"rouge2\"`) where: {n} is the n-gram based scoring,\n",
       "        `\"rougeL\"`: Longest common subsequence based scoring.\n",
       "        `\"rougeLsum\"`: rougeLsum splits text using `\"\n",
       "\"`.\n",
       "        See details in https://github.com/huggingface/datasets/issues/617\n",
       "    use_stemmer: Bool indicating whether Porter stemmer should be used to strip word suffixes.\n",
       "    use_aggregator: Return aggregates if this is set to True\n",
       "Returns:\n",
       "    rouge1: rouge_1 (f1),\n",
       "    rouge2: rouge_2 (f1),\n",
       "    rougeL: rouge_l (f1),\n",
       "    rougeLsum: rouge_lsum (f1)\n",
       "Examples:\n",
       "\n",
       "    >>> rouge = evaluate.load('rouge')\n",
       "    >>> predictions = [\"hello there\", \"general kenobi\"]\n",
       "    >>> references = [\"hello there\", \"general kenobi\"]\n",
       "    >>> results = rouge.compute(predictions=predictions, references=references)\n",
       "    >>> print(results)\n",
       "    {'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    preds, labels = pred\n",
    "    decode_pred = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_type_id)\n",
    "    decode_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    rouge_metric = rouge.compute(predictions=decode_pred, references=decode_labels, use_stemmer = True)\n",
    "    prediction_lens = [np.count_nonzero(pred!=tokenizer.pad_token_type_id) for pred in preds]\n",
    "    rouge_metric[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    return {k: round(v,4) for k,v in rouge_metric.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"text_summarizerv1\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16, \n",
    "    per_device_eval_batch_size=16, \n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3, \n",
    "    num_train_epochs=4, \n",
    "    predict_with_generate=True,\n",
    "    report_to=\"wandb\",\n",
    "    fp16=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer =Seq2SeqTrainer(\n",
    "    model = model, \n",
    "    args= training_args,\n",
    "    train_dataset=billsum_tokeniz[\"train\"], \n",
    "    eval_dataset=billsum_tokeniz[\"test\"],\n",
    "    processing_class=tokenizer, \n",
    "    data_collator= data_collator, \n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "  0%|          | 0/232 [00:00<?, ?it/s]Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      " 25%|██▌       | 58/232 [00:55<02:32,  1.14it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      " 10%|█         | 2/20 [00:00<00:07,  2.55it/s]\n",
      " 15%|█▌        | 3/20 [00:01<00:09,  1.78it/s]\n",
      " 20%|██        | 4/20 [00:02<00:10,  1.57it/s]\n",
      " 25%|██▌       | 5/20 [00:03<00:10,  1.47it/s]\n",
      " 30%|███       | 6/20 [00:03<00:09,  1.41it/s]\n",
      " 35%|███▌      | 7/20 [00:04<00:09,  1.37it/s]\n",
      " 40%|████      | 8/20 [00:05<00:08,  1.35it/s]\n",
      " 45%|████▌     | 9/20 [00:06<00:08,  1.34it/s]\n",
      " 50%|█████     | 10/20 [00:06<00:07,  1.33it/s]\n",
      " 55%|█████▌    | 11/20 [00:07<00:06,  1.32it/s]\n",
      " 60%|██████    | 12/20 [00:08<00:06,  1.31it/s]\n",
      " 65%|██████▌   | 13/20 [00:09<00:05,  1.32it/s]\n",
      " 70%|███████   | 14/20 [00:09<00:04,  1.32it/s]\n",
      " 75%|███████▌  | 15/20 [00:10<00:03,  1.32it/s]\n",
      " 80%|████████  | 16/20 [00:11<00:03,  1.32it/s]\n",
      " 85%|████████▌ | 17/20 [00:12<00:02,  1.29it/s]\n",
      " 90%|█████████ | 18/20 [00:13<00:01,  1.27it/s]\n",
      " 95%|█████████▌| 19/20 [00:13<00:00,  1.25it/s]\n",
      "                                                \n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8220036029815674, 'eval_rouge1': 0.1283, 'eval_rouge2': 0.0393, 'eval_rougeL': 0.1055, 'eval_rougeLsum': 0.1055, 'eval_gen_len': 20.0, 'eval_runtime': 16.0072, 'eval_samples_per_second': 19.366, 'eval_steps_per_second': 1.249, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 58/232 [01:11<02:32,  1.14it/s]\n",
      "100%|██████████| 20/20 [00:15<00:00,  1.47it/s]\n",
      " 50%|█████     | 116/232 [02:04<01:32,  1.25it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      " 10%|█         | 2/20 [00:00<00:06,  2.82it/s]\n",
      " 15%|█▌        | 3/20 [00:01<00:08,  1.96it/s]\n",
      " 20%|██        | 4/20 [00:02<00:09,  1.71it/s]\n",
      " 25%|██▌       | 5/20 [00:02<00:09,  1.58it/s]\n",
      " 30%|███       | 6/20 [00:03<00:09,  1.50it/s]\n",
      " 35%|███▌      | 7/20 [00:04<00:08,  1.46it/s]\n",
      " 40%|████      | 8/20 [00:05<00:08,  1.44it/s]\n",
      " 45%|████▌     | 9/20 [00:05<00:07,  1.42it/s]\n",
      " 50%|█████     | 10/20 [00:06<00:07,  1.41it/s]\n",
      " 55%|█████▌    | 11/20 [00:07<00:06,  1.41it/s]\n",
      " 60%|██████    | 12/20 [00:07<00:05,  1.40it/s]\n",
      " 65%|██████▌   | 13/20 [00:08<00:04,  1.40it/s]\n",
      " 70%|███████   | 14/20 [00:09<00:04,  1.40it/s]\n",
      " 75%|███████▌  | 15/20 [00:10<00:03,  1.40it/s]\n",
      " 80%|████████  | 16/20 [00:10<00:02,  1.40it/s]\n",
      " 85%|████████▌ | 17/20 [00:11<00:02,  1.40it/s]\n",
      " 90%|█████████ | 18/20 [00:12<00:01,  1.39it/s]\n",
      " 95%|█████████▌| 19/20 [00:12<00:00,  1.39it/s]\n",
      "                                                 \n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5943057537078857, 'eval_rouge1': 0.1374, 'eval_rouge2': 0.0482, 'eval_rougeL': 0.1121, 'eval_rougeLsum': 0.1121, 'eval_gen_len': 20.0, 'eval_runtime': 14.8041, 'eval_samples_per_second': 20.94, 'eval_steps_per_second': 1.351, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 116/232 [02:19<01:32,  1.25it/s]\n",
      "100%|██████████| 20/20 [00:14<00:00,  1.64it/s]\n",
      " 75%|███████▌  | 174/232 [03:09<00:47,  1.23it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      " 10%|█         | 2/20 [00:00<00:06,  2.80it/s]\n",
      " 15%|█▌        | 3/20 [00:01<00:08,  1.97it/s]\n",
      " 20%|██        | 4/20 [00:02<00:09,  1.72it/s]\n",
      " 25%|██▌       | 5/20 [00:02<00:09,  1.59it/s]\n",
      " 30%|███       | 6/20 [00:03<00:09,  1.52it/s]\n",
      " 35%|███▌      | 7/20 [00:04<00:08,  1.47it/s]\n",
      " 40%|████      | 8/20 [00:05<00:08,  1.45it/s]\n",
      " 45%|████▌     | 9/20 [00:05<00:07,  1.42it/s]\n",
      " 50%|█████     | 10/20 [00:06<00:07,  1.42it/s]\n",
      " 55%|█████▌    | 11/20 [00:07<00:06,  1.41it/s]\n",
      " 60%|██████    | 12/20 [00:07<00:05,  1.41it/s]\n",
      " 65%|██████▌   | 13/20 [00:08<00:05,  1.40it/s]\n",
      " 70%|███████   | 14/20 [00:09<00:04,  1.40it/s]\n",
      " 75%|███████▌  | 15/20 [00:10<00:03,  1.40it/s]\n",
      " 80%|████████  | 16/20 [00:10<00:02,  1.40it/s]\n",
      " 85%|████████▌ | 17/20 [00:11<00:02,  1.41it/s]\n",
      " 90%|█████████ | 18/20 [00:12<00:01,  1.40it/s]\n",
      " 95%|█████████▌| 19/20 [00:12<00:00,  1.40it/s]\n",
      "                                                 \n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5324058532714844, 'eval_rouge1': 0.1414, 'eval_rouge2': 0.0497, 'eval_rougeL': 0.1158, 'eval_rougeLsum': 0.1159, 'eval_gen_len': 20.0, 'eval_runtime': 14.7292, 'eval_samples_per_second': 21.047, 'eval_steps_per_second': 1.358, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 174/232 [03:24<00:47,  1.23it/s]\n",
      "100%|██████████| 20/20 [00:14<00:00,  1.65it/s]\n",
      "100%|██████████| 232/232 [04:14<00:00,  1.25it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      " 10%|█         | 2/20 [00:00<00:06,  2.85it/s]\n",
      " 15%|█▌        | 3/20 [00:01<00:08,  1.98it/s]\n",
      " 20%|██        | 4/20 [00:02<00:09,  1.69it/s]\n",
      " 25%|██▌       | 5/20 [00:02<00:09,  1.56it/s]\n",
      " 30%|███       | 6/20 [00:03<00:09,  1.51it/s]\n",
      " 35%|███▌      | 7/20 [00:04<00:08,  1.47it/s]\n",
      " 40%|████      | 8/20 [00:05<00:08,  1.44it/s]\n",
      " 45%|████▌     | 9/20 [00:05<00:07,  1.42it/s]\n",
      " 50%|█████     | 10/20 [00:06<00:07,  1.41it/s]\n",
      " 55%|█████▌    | 11/20 [00:07<00:06,  1.39it/s]\n",
      " 60%|██████    | 12/20 [00:07<00:05,  1.39it/s]\n",
      " 65%|██████▌   | 13/20 [00:08<00:05,  1.39it/s]\n",
      " 70%|███████   | 14/20 [00:09<00:04,  1.39it/s]\n",
      " 75%|███████▌  | 15/20 [00:10<00:03,  1.39it/s]\n",
      " 80%|████████  | 16/20 [00:10<00:02,  1.40it/s]\n",
      " 85%|████████▌ | 17/20 [00:11<00:02,  1.39it/s]\n",
      " 90%|█████████ | 18/20 [00:12<00:01,  1.40it/s]\n",
      " 95%|█████████▌| 19/20 [00:12<00:00,  1.39it/s]\n",
      "                                                 \n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5171501636505127, 'eval_rouge1': 0.1434, 'eval_rouge2': 0.0516, 'eval_rougeL': 0.118, 'eval_rougeLsum': 0.1178, 'eval_gen_len': 20.0, 'eval_runtime': 14.8075, 'eval_samples_per_second': 20.935, 'eval_steps_per_second': 1.351, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [04:29<00:00,  1.25it/s]\n",
      "100%|██████████| 20/20 [00:14<00:00,  1.64it/s]\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 269.4984, 'train_samples_per_second': 13.759, 'train_steps_per_second': 0.861, 'train_loss': 3.109038780475485, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [04:29<00:00,  1.16s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=232, training_loss=3.109038780475485, metrics={'train_runtime': 269.4984, 'train_samples_per_second': 13.759, 'train_steps_per_second': 0.861, 'total_flos': 1003694799716352.0, 'train_loss': 3.109038780475485, 'epoch': 4.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/gen_len</td><td>▁▁▁▁</td></tr><tr><td>eval/loss</td><td>█▃▁▁</td></tr><tr><td>eval/rouge1</td><td>▁▅▇█</td></tr><tr><td>eval/rouge2</td><td>▁▆▇█</td></tr><tr><td>eval/rougeL</td><td>▁▅▇█</td></tr><tr><td>eval/rougeLsum</td><td>▁▅▇█</td></tr><tr><td>eval/runtime</td><td>█▁▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▁███</td></tr><tr><td>eval/steps_per_second</td><td>▁███</td></tr><tr><td>train/epoch</td><td>▁▃▆██</td></tr><tr><td>train/global_step</td><td>▁▃▆██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/gen_len</td><td>20</td></tr><tr><td>eval/loss</td><td>2.51715</td></tr><tr><td>eval/rouge1</td><td>0.1434</td></tr><tr><td>eval/rouge2</td><td>0.0516</td></tr><tr><td>eval/rougeL</td><td>0.118</td></tr><tr><td>eval/rougeLsum</td><td>0.1178</td></tr><tr><td>eval/runtime</td><td>14.8075</td></tr><tr><td>eval/samples_per_second</td><td>20.935</td></tr><tr><td>eval/steps_per_second</td><td>1.351</td></tr><tr><td>total_flos</td><td>1003694799716352.0</td></tr><tr><td>train/epoch</td><td>4</td></tr><tr><td>train/global_step</td><td>232</td></tr><tr><td>train_loss</td><td>3.10904</td></tr><tr><td>train_runtime</td><td>269.4984</td></tr><tr><td>train_samples_per_second</td><td>13.759</td></tr><tr><td>train_steps_per_second</td><td>0.861</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">briefly-trialsv1</strong> at: <a href='https://wandb.ai/abhinavm16104-delhi-skill-and-entrepreneurship-university/briefly-v1/runs/9f0s9g0e' target=\"_blank\">https://wandb.ai/abhinavm16104-delhi-skill-and-entrepreneurship-university/briefly-v1/runs/9f0s9g0e</a><br> View project at: <a href='https://wandb.ai/abhinavm16104-delhi-skill-and-entrepreneurship-university/briefly-v1' target=\"_blank\">https://wandb.ai/abhinavm16104-delhi-skill-and-entrepreneurship-university/briefly-v1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241220_125340-9f0s9g0e\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenix-textsum-v1\\\\tokenizer_config.json',\n",
       " 'tokenix-textsum-v1\\\\special_tokens_map.json',\n",
       " 'tokenix-textsum-v1\\\\spiece.model',\n",
       " 'tokenix-textsum-v1\\\\added_tokens.json',\n",
       " 'tokenix-textsum-v1\\\\tokenizer.json')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('textsum-v1-model')\n",
    "tokenizer.save_pretrained('tokenix-textsum-v1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
